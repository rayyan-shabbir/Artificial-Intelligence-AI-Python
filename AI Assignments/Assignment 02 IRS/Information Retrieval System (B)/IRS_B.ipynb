{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2 IRS - With Synonyms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Information retrieval is the process of obtaining information system resources that are relevant to an information need from a collection of those resources. The core purpose of this assignment is to give you the flavor of IRS. You need to follow some steps listed below and in the end, you'll be able to build your own small IRS. So, let's start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# required imports\n",
    "import numpy as np\n",
    "import fnmatch\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we have 3 files containing data :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Contents"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"This is my book\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f1.png?raw=true)\n",
    "![\"This is my pen\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f2.png?raw=true)\n",
    "![\"This is book is intersting\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/f3.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1 Create Files with Dummy data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have to create few files with dummy data of your own choice as shown above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2 Traverse Directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Now, You have to traverse the directories and store all the files into a dict type variable(files_dict). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we have initialized some variables, you can add more if required.\n",
    "\n",
    "file_count = 0             # file_count to count number of files\n",
    "files_dict = {}            # files_dic to store count of every file    \n",
    "unique_word_set = set()    # unique_word_set to store all the unique words in a set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n",
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 0, 'f3.txt': 0}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "file_count=0\n",
    "files_dict={}\n",
    "\n",
    "name = 'f*.txt'     #since I have  created the file1,2,3 with extension txt which contain data so for specification of file type i write this\n",
    "#file_path=input(\"Enter the file path where you have files containing data ? \")\n",
    "#file_path = 'D:\\\\5th semester\\\\ML\\\\Assignmnet 2 - IRS\\\\files'\n",
    "files = os.listdir('.')           #it will contain the all files which are in the current directory   \n",
    "for i in files:                     #iterating all the files\n",
    "    if  fnmatch.fnmatch(i, name) :    #it will check the files having f as their first word and .txt extension\n",
    "        file_count=file_count+1;              #if found it will add 1 in variable\n",
    "        #print(i)\n",
    "        #files_dict[file_count] = i      # it will  create dictionary having key values (i =file name) and items (files count 1,2,3)\n",
    "        files_dict[i] = 0               #it will  create dictionary having items (keys) (i =file name of only which is True (f*.txt)) and  values =0\n",
    "print(\"\\nTotal Number  of files\\n\", file_count)\n",
    "print(\"\\nDictionary containing  files\\n\", files_dict)\n",
    "#Your code ends here       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the count of files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total Number  of files\n",
      " 3\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTotal Number  of files\\n\", file_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying Dictionary containing all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dictionary containing  files\n",
      " {'f1.txt': 0, 'f2.txt': 0, 'f3.txt': 0}\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nDictionary containing  files\\n\", files_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3 Extract Unique Vocabulary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "write code to print all the unique words in every file and store them in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'pen', 'is', 'book', 'this', 'interesting', 'my'}\n",
      "\n",
      "Count of files   3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "unique_word_set = set()         #declaring a set for unique words\n",
    "#files_dict = {'f1.txt': 0, 'f2.txt': 0,'f3.txt' :0}\n",
    "for i  in files_dict :    #iterating through files_dict which have f1,f2,f3\n",
    "    fhand=open (i)         #it will open the file\n",
    "    for line in fhand:      \n",
    "        words = line.split()       #it will separate  words of each line as list\n",
    "        for word in words:          #iterate each word in list \n",
    "            lower = word.lower()       # as in file caps aslo user like This or this to consider both as same we are converting in lower alphabets  \n",
    "            if lower not in unique_word_set:   #since no word should come twice in set as it is unique so checking if it isn't already in set\n",
    "              unique_word_set.add(lower)      #if not already there add it\n",
    "                \n",
    "           \n",
    "print (unique_word_set)\n",
    "print(\"\\nCount of files  \", file_count)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o1.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4 Create Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Term-Doc-matrix using Bag of word approach.and display its contents initially and finally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Create Term doc matrix such that colmns will be unique words and all the files will be rows\n",
    "2. Write code to count all the unique words appearances in all the files and store it in a dictionary for words "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0]]\n",
      "{'pen': 0, 'is': 1, 'book': 2, 'this': 3, 'interesting': 4, 'my': 5}\n",
      "Dictionary of files\n",
      "{'f1.txt': 0, 'f2.txt': 1, 'f3.txt': 2}\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here\n",
    "#Your code starts here    \n",
    "import numpy\n",
    "\n",
    "i=0\n",
    "j=0\n",
    "dict_uwords={}             #to have dictionary of unique words\n",
    "doc_matrix = numpy.full((file_count,len(unique_word_set)), 0)    #it will create matrix haing rows equal to files no (3) column = no of unique words\n",
    "print(doc_matrix)\n",
    "for item in unique_word_set :       #iterating through each unique word from set\n",
    "    dict_uwords[item]=i             #then adding that word as key in dict_uwords and value of that (each) key\n",
    "    i=i+1                            #is incrementing by 1 (as we need unique ids)\n",
    "for file in files_dict :            #iterating through each file from file_dict\n",
    "    files_dict[file]=j              #giving each file (key) a value of i \n",
    "    j=j+1                           #j is  incrementing by 1 (as we need unique ids)\n",
    "\n",
    "print(dict_uwords) \n",
    "print(\"Dictionary of files\")\n",
    "print(files_dict)  \n",
    "    \n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o2.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5 Fill Term Document Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Fill the term doc matrix by checking if the unique word exists in a file or not\n",
    "2. If it exists then substitute a 1 in term_doc_matrix (eg : TERM_DOC_MATRIX[file][word] = 1 ) \n",
    "3. Do the same for all the files present in the directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary of unique words\n",
      "{'pen': 0, 'is': 1, 'book': 2, 'this': 3, 'interesting': 4, 'my': 5}\n",
      "\n",
      "Term Matrix Document\n",
      "[[0 1 1 1 0 1]\n",
      " [1 1 0 1 0 1]\n",
      " [0 1 1 0 1 1]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "i=0 \n",
    "for i,file in enumerate(files_dict):  #iterating through file_dict by using this built-in function as this will give two things index ,0,1,2 and keys of dict\n",
    "    fhand= open(file,'r')              #opening file in read mode\n",
    "    words = fhand.read().lower().split()    #again this will read lines and convert into lower so that This and this type scenario can be dealt \n",
    "                                           #this will create list for each file seprating each word as['this', 'is', 'my', 'book]\n",
    "     # print(words) \n",
    "    for j,word in enumerate(dict_uwords) :  #iterating through dict of unique words by using =built-in function as this will give two things index ,0,1,2 and keys of dict\n",
    "        if word in words:                   #checking if the word in unique word set is in file \n",
    "            doc_matrix[i, j] = 1            #if yes then TERM_DOC_MATRIX[file][word] = 1 here i is  index of file and j is index of unqiue word \n",
    "print(\"Dictionary of unique words\")   \n",
    "print(dict_uwords)\n",
    "print(\"\\nTerm Matrix Document\")\n",
    "print(doc_matrix)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o4.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6 Ask for a user Query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For user query make a column vector of length of all the unique words present in a set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "colVector Initially \n",
      "[[0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "\n",
    "import numpy\n",
    "query_vector=numpy.full((len(dict_uwords),1), 0)  #creating a matrix having rows no = to no of unique words and filling it with zero\n",
    "print(\"colVector Initially \")\n",
    "print(query_vector)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o5.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query is: this is a fascinating publication written with a ballpoint\n"
     ]
    }
   ],
   "source": [
    "query = input(\"\\nWrite something for searching:  \")\n",
    "print(\"Query is:\", query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Expected Output of query](images/Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Load Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'write': ['compose,draft,author,create'], 'file': ['document,record,dossier,report'], 'example': ['illustration,instance,sample,demonstration'], 'query': ['question', 'inquiry', 'search', 'request'], 'synonym': ['equivalent', 'substitute', 'alternate', 'replacement'], 'retrieve': ['fetch', 'recover', 'obtain', 'bring back'], 'system': ['framework', 'structure', 'organization', 'arrangement'], 'search': ['seek', 'look for', 'explore', 'examine'], 'lost': ['misplaced', 'missing', 'forgotten', 'mislaid'], 'pen': ['write', 'ink', 'ballpoint', 'fountain'], 'paper': ['document', 'sheet', 'form', 'letter'], 'book': ['novel', 'volume', 'publication', 'tome'], 'read': ['peruse', 'scan', 'study', 'look at'], 'interesting': ['fascinating', 'engaging', 'intriguing', 'absorbing'], 'computer': ['machine', 'device', 'processor', 'laptop'], 'software': ['program', 'application', 'app', 'platform']}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'word=query.split()\\nsynonyms_dict = {} # dictionary to store synonyms\\nfor lines in fhand :\\n    word_line=lines\\n    \\n   # print(word_line)\\n    for word1 in word:\\n       # print(word1)\\n           if word1 in word_line :\\n             if word1 in  lines :\\n                if word1 not in synonyms_dict:\\n                    synonyms_dict[word1] = []\\n                    \\n                       \\n                    synonyms_dict[word1].append(word_line)\\n\\n#your code ends here\\n\\nprint(\"\\nSynonyms Dictionary\\n\")\\nprint(synonyms_dict)'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#your code starts here\n",
    "synonym_file_path = r\"files\\synonyms.txt\"\n",
    "fhand =open('synonyms.txt')\n",
    "synonyms_dict = {}\n",
    "\n",
    "for lines in fhand :     #iterating through each line of file \n",
    "    k=lines.split(':')   #spliting the line in two parts in list by using : as separator this will separate the key word and the list of synonyms words \n",
    "    \n",
    "    for i in range(len(k)-1): #this will iterate the list as list has 2 parts mean size=2 so i did len(k)-1 because i just want to iterate 0,1 index\n",
    "        key=k[i]            #this will store the 1st element(before colon ) of list in key variable \n",
    "        val=k[i+1].strip().split((', '))    #this will store the 2nd element(after colon ) of list in val list as we are spliting either by ,\n",
    "                                            #space since 1st three rows in file  in expected output , is not dealt as separator but in other ,space\n",
    "        \n",
    "        synonyms_dict[key]=val\n",
    "\n",
    "\n",
    "print(synonyms_dict)   \n",
    "\n",
    "#commenting this becz first i thought that we are supposed to take word from user and  show all its synonyms like a:b,c,d if user say b so we have to show b:a,c,d\n",
    "'''word=query.split()\n",
    "synonyms_dict = {} # dictionary to store synonyms\n",
    "for lines in fhand :\n",
    "    word_line=lines\n",
    "    \n",
    "   # print(word_line)\n",
    "    for word1 in word:\n",
    "       # print(word1)\n",
    "           if word1 in word_line :\n",
    "             if word1 in  lines :\n",
    "                if word1 not in synonyms_dict:\n",
    "                    synonyms_dict[word1] = []\n",
    "                    \n",
    "                       \n",
    "                    synonyms_dict[word1].append(word_line)\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"\\nSynonyms Dictionary\\n\")\n",
    "print(synonyms_dict)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Synonym Dict Example](images\\Synonym_dict.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Extend User Query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expanded Query\n",
      "['this', 'is', 'a', 'fascinating', 'interesting', 'publication', 'book', 'written', 'with', 'a', 'ballpoint', 'pen']\n"
     ]
    }
   ],
   "source": [
    "expanded_query = []\n",
    "# Write code to expand the query using synonyms\n",
    "#your code starts here\n",
    "\n",
    "expanded_query=query.split()  #using split to separate the words of query \n",
    "for index,part in enumerate(expanded_query):  # as we have to insertv synonym words in query so we need index that why using this built func part will contain words of query\n",
    "    for i in synonyms_dict:    #iterating thorugh the sysnonyms dictionary \n",
    "        ans=synonyms_dict[i]   #storing the values of each key (word )in dic as ans list\n",
    "        if part in ans :        #if query word is in the list of words (synonyms) values o key in dic of synonyms\n",
    "            expanded_query.insert((index+1),i)   #the in the next index of that query word add the key word \n",
    "\n",
    "\n",
    "#your code ends here\n",
    "\n",
    "print(\"Expanded Query\")\n",
    "print(expanded_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Extended Query](images\\Expanded_Query.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now work with extended query and find the relevant documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check every word of query if it exists in the set of unique words or not\n",
    "# If exists then increment the count of that word in word dictionary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Col Vector after query \n",
      "[[1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here   \n",
    "import numpy\n",
    "words=expanded_query               #spliting the query as a list so that we can deal it as separate word\n",
    "query_vector=numpy.full((len(dict_uwords),1), 0)  #creating a matrix having rows no = to no of unique words and 1 column and filling it with zero\n",
    "for word in words:         #iterating each word of query        \n",
    "        if word in dict_uwords:     #checing if word in query is also in unique words dictionary\n",
    "            #print(word)\n",
    "            #print(j)\n",
    "            query_vector[dict_uwords[word],0]=query_vector[dict_uwords[word],0]+1  #if yes the 0 column and row (which is representing the unique id of that unique word) add 1 into it each time we find that word\n",
    "print(\"Col Vector after query \")\n",
    "print(query_vector)\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o6.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 7 Display Resultant Vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display \n",
    "1. Resultant vector.\n",
    "2. Max value in resultant vector.\n",
    "3. Index of max value in resultant vector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result  [[3]\n",
      " [3]\n",
      " [3]]\n",
      "max index\n",
      "  0\n",
      "max\n",
      "  3\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here  \n",
    "#Your code starts here  \n",
    "resultant_vec=numpy.full((file_count,1),0)  #creating a matrix having rows no = to no of files and 1 colum\n",
    "max_v=0\n",
    "resultant_vec=doc_matrix.dot(query_vector)   # multiplying the two matrix the query one and doc (representing words in files) to check the max of matching words we are having\n",
    "print(\"Result \" , resultant_vec)\n",
    "for i in resultant_vec :  # itering rows of resultant matrix\n",
    "    #print(i)\n",
    "    for j in i :   # itering all columns values of rows (00,01,02,03...10,11,) of resultant matrix\n",
    "        #print(j)\n",
    "        if j>max_v :   #checking if column value is large then stroing it in max\n",
    "            max_v=j\n",
    "            max_index=numpy.argmax(resultant_vec)    #built in function to find the index having max value \n",
    "print(\"max index\\n \", max_index)\n",
    "print(\"max\\n \", max_v)\n",
    "\n",
    "#Your code ends here\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![\"Expected Output of unique words\" - File 1](https://github.com/ahmad-14a/CS-F20-ML/blob/main/IRS-Assignment%201/o7.png?raw=true)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 8 Display the contents of file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write the code to identify the file_name having maximum value in the resultant vector and display its contents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is my book\n"
     ]
    }
   ],
   "source": [
    "#Your code starts here    \n",
    "c = -1  \n",
    "\n",
    "for file in files_dict:\n",
    "    c += 1\n",
    "    if c == max_index:  # Open the file when c reaches the desired index\n",
    "        fhand =open(file, 'r')  # Use `with` for proper file closure\n",
    "        for line in fhand:\n",
    "            print(line)\n",
    "\n",
    "#Your code ends here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations Now you are able to build your own small IRS which can work even if query does not have exact same words."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
